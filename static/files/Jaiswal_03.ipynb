{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Divide the dataset as train, development, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and Combine data from the given dataset (.tar.gz file)\n",
    "# Note: This will take a long time to execute as the data is in distinct files and very large\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_dev_test = pd.DataFrame()\n",
    "df_dev = pd.DataFrame()\n",
    "df_test = pd.DataFrame()\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "\n",
    "tar = tarfile.open(\"aclImdb_v1.tar.gz\", \"r:gz\")\n",
    "for member in tar.getmembers():\n",
    "    f = tar.extractfile(member)\n",
    "    if f is not None:\n",
    "        if(member.name.find('aclImdb/train/pos/') != -1):\n",
    "            content = f.read().decode('utf-8')\n",
    "            df_train = df_train.append([[content, labels['pos']]],\n",
    "                           ignore_index=True)\n",
    "            \n",
    "        if(member.name.find('aclImdb/train/neg/') != -1):\n",
    "            content = f.read().decode('utf-8')\n",
    "            df_train = df_train.append([[content, labels['neg']]],\n",
    "                           ignore_index=True)\n",
    "            \n",
    "        if(member.name.find('aclImdb/test/pos/') != -1):\n",
    "            content = f.read().decode('utf-8')\n",
    "            df_dev_test = df_dev_test.append([[content, labels['pos']]],\n",
    "                           ignore_index=True)\n",
    "            \n",
    "        if(member.name.find('aclImdb/test/neg/') != -1):\n",
    "            content = f.read().decode('utf-8')\n",
    "            df_dev_test = df_dev_test.append([[content, labels['neg']]],\n",
    "                           ignore_index=True)\n",
    "            \n",
    "df_train.columns = ['review', 'sentiment']\n",
    "df_dev_test.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframes in test folder randomly into dev and test dataframes\n",
    "\n",
    "spdf = np.random.rand(len(df_dev_test)) < 0.6\n",
    "\n",
    "df_dev = df_dev_test[spdf]\n",
    "df_test = df_dev_test[~spdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train records: 25000\n",
      "positive records: 12500\n",
      "negative records: 12500\n",
      "prob positive records: 0.5\n",
      "prob negative records: 0.5\n",
      "\n",
      "total dev records: 15059\n",
      "total test records: 9941\n"
     ]
    }
   ],
   "source": [
    "# Print information regarding records in each dataset\n",
    "\n",
    "df_train_len = len(df_train)\n",
    "print('total train records:', df_train_len)\n",
    "\n",
    "df_train_pos_len = len(df_train[df_train['sentiment'] == 1])\n",
    "df_train_neg_len = len(df_train[df_train['sentiment'] == 0])\n",
    "prob_pos_train = df_train_pos_len / df_train_len\n",
    "prob_neg_train = df_train_neg_len / df_train_len\n",
    "\n",
    "print ('positive records:', df_train_pos_len)\n",
    "print ('negative records:', df_train_neg_len)\n",
    "\n",
    "print ('prob positive records:', prob_pos_train)\n",
    "print ('prob negative records:', prob_neg_train)\n",
    "\n",
    "print()\n",
    "print('total dev records:', len(df_dev))\n",
    "print('total test records:', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0           12500\n",
       "1           12500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print count of each sentiment in train dataset\n",
    "df_train.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0            7443\n",
       "1            7616"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print count of each sentiment in dev dataset\n",
    "df_dev.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           review\n",
       "sentiment        \n",
       "0            5057\n",
       "1            4884"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print count of each sentiment in test dataset\n",
    "df_test.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV files for each dataframe\n",
    "\n",
    "np.random.seed(0)\n",
    "df_train = df_train.reindex(np.random.permutation(df_train.index))\n",
    "df_train.to_csv('movie_data_train.csv', index=False, encoding = 'utf-8')\n",
    "\n",
    "np.random.seed(0)\n",
    "df_dev = df_dev.reindex(np.random.permutation(df_dev.index))\n",
    "df_dev.to_csv('movie_data_dev.csv', index=False, encoding = 'utf-8')\n",
    "\n",
    "np.random.seed(0)\n",
    "df_test = df_test.reindex(np.random.permutation(df_test.index))\n",
    "df_test.to_csv('movie_data_test.csv', index=False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fräulein Doktor is as good a demonstration as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I watched this knowing almost nothing about it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I must give How She Move a near-perfect rating...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The storyline is absurd and lame,also sucking ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I watched Grendel the other night and am compe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Fräulein Doktor is as good a demonstration as ...          1\n",
       "1  I watched this knowing almost nothing about it...          0\n",
       "2  I must give How She Move a near-perfect rating...          1\n",
       "3  The storyline is absurd and lame,also sucking ...          0\n",
       "4  I watched Grendel the other night and am compe...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print train data\n",
    "df_train = pd.read_csv('movie_data_train.csv', encoding = 'utf-8')\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Scary Movie 1-4, Epic Movie, Date Movie, Meet ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>This is a funny, intelligent and, in a sense, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I give this movie 2 stars purely because of it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>When at the very start of the film Paleontolog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I saw this movie awhile back and can't seem to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Scary Movie 1-4, Epic Movie, Date Movie, Meet ...          0\n",
       "1  This is a funny, intelligent and, in a sense, ...          1\n",
       "2  I give this movie 2 stars purely because of it...          0\n",
       "3  When at the very start of the film Paleontolog...          0\n",
       "4  I saw this movie awhile back and can't seem to...          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dev_data\n",
    "df_dev = pd.read_csv('movie_data_dev.csv', encoding = 'utf-8')\n",
    "df_dev.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I've been a fan of Larry King's show for awhil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>THE FEELING of the need to have someone play t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Bride of Chucky\" is one of the better horror ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I just purchased this movie because I love to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This film is great - well written and very ent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I've been a fan of Larry King's show for awhil...          1\n",
       "1  THE FEELING of the need to have someone play t...          1\n",
       "2  \"Bride of Chucky\" is one of the better horror ...          1\n",
       "3  I just purchased this movie because I love to ...          0\n",
       "4  This film is great - well written and very ent...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print test data\n",
    "df_test = pd.read_csv('movie_data_test.csv', encoding = 'utf-8')\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "# Calculate length of training dataset\n",
    "\n",
    "doc_len = len(df_train)\n",
    "print(doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the possible special characters to get proper words\n",
    "\n",
    "df_train.columns = df_train.columns.str.strip()         \n",
    "df_train.columns = df_train.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")    \n",
    "df_train.columns = df_train.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")\n",
    "\n",
    "df_dev.columns = df_dev.columns.str.strip()         \n",
    "df_dev.columns = df_dev.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")    \n",
    "df_dev.columns = df_dev.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")\n",
    "\n",
    "df_test.columns = df_test.columns.str.strip()         \n",
    "df_test.columns = df_test.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")    \n",
    "df_test.columns = df_test.columns.str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")\n",
    "\n",
    "df_train = df_train.replace([\";\",\":\",\"=\",\"\\+\",\"<\", \">\", \"\\?\", \"!\", \"\\\\\\\\\", \"@\", \"#\", \"$\", \"\\*\", \"%\", \",\", \"\\.\", \"\\(\", \"\\)\", \"\\[\", \"\\]\", \"\\{\", \"\\}\", \"\\\"\", \"/br\"], \"\", regex = True)\n",
    "df_dev = df_dev.replace([\";\",\":\",\"=\",\"\\+\",\"<\", \">\", \"\\?\", \"!\", \"\\\\\\\\\", \"@\", \"#\", \"$\", \"\\*\", \"%\", \",\", \"\\.\", \"\\(\", \"\\)\", \"\\[\", \"\\]\", \"\\{\", \"\\}\", \"\\\"\", \"/br\"], \"\", regex = True)\n",
    "df_test = df_test.replace([\";\",\":\",\"=\",\"\\+\",\"<\", \">\", \"\\?\", \"!\", \"\\\\\\\\\", \"@\", \"#\", \"$\", \"\\*\", \"%\", \",\", \"\\.\", \"\\(\", \"\\)\", \"\\[\", \"\\]\", \"\\{\", \"\\}\", \"\\\"\", \"/br\"], \"\", regex = True)\n",
    "\n",
    "df_train = df_train.replace([\"' \", \" '\"], \" \", regex = True)\n",
    "df_dev = df_dev.replace([\"' \", \" '\"], \" \", regex = True)\n",
    "df_test = df_test.replace([\"' \", \" '\"], \" \", regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Build a vocabulary as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency for each vocab\n",
    "\n",
    "wordfreq = dict()\n",
    "wordfreq_pos = dict()\n",
    "wordfreq_neg = dict()\n",
    "for ind in df_train.index:\n",
    "    review_set = set(df_train['review'][ind].lower().split())\n",
    "    for word in review_set:\n",
    "        if word in wordfreq:\n",
    "            wordfreq[word] += 1\n",
    "        else:\n",
    "            wordfreq[word] = 1\n",
    "        \n",
    "        if df_train['sentiment'][ind] == 1:\n",
    "            if word in wordfreq_pos:\n",
    "                wordfreq_pos[word] += 1\n",
    "            else:\n",
    "                wordfreq_pos[word] = 1\n",
    "        else:\n",
    "            if word in wordfreq_neg:\n",
    "                wordfreq_neg[word] += 1\n",
    "            else:\n",
    "                wordfreq_neg[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ommiting rare vocabs having frequency < 5\n",
    "\n",
    "final_vocab = dict()\n",
    "final_vocab_pos = dict()\n",
    "final_vocab_neg = dict()\n",
    "for word in wordfreq:\n",
    "    if wordfreq[word] > 5:\n",
    "        final_vocab[word] = wordfreq[word]\n",
    "    if word in wordfreq_pos:\n",
    "        if wordfreq_pos[word] > 5:\n",
    "            final_vocab_pos[word] = wordfreq_pos[word]\n",
    "    if word in wordfreq_neg:\n",
    "        if wordfreq_neg[word] > 5:\n",
    "            final_vocab_neg[word] = wordfreq_neg[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocab: 27681\n"
     ]
    }
   ],
   "source": [
    "# Print count of filtered vocab\n",
    "print(\"Total Vocab:\",len(final_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Calculate the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities for:\n",
    "# a) each word\n",
    "# b) each word given positive\n",
    "# c) each word given negative\n",
    "\n",
    "prob_word = dict()\n",
    "prob_word_g_pos = dict()\n",
    "prob_word_g_neg = dict()\n",
    "\n",
    "for word in final_vocab:\n",
    "    prob_word[word] = final_vocab[word] / doc_len\n",
    "    if word in final_vocab_pos:\n",
    "        prob_word_g_pos[word] = final_vocab_pos[word] / df_train_pos_len\n",
    "        \n",
    "    if word in final_vocab_neg:\n",
    "        prob_word_g_neg[word] = final_vocab_neg[word] / df_train_neg_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Calculate accuracy using dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using 5-Fold Cross Validation:\n",
      "1 : Accuracy df_dev: 61.254980079681275 %\n",
      "2 : Accuracy df_dev: 61.75298804780876 %\n",
      "3 : Accuracy df_dev: 63.081009296148736 %\n",
      "4 : Accuracy df_dev: 62.35059760956175 %\n",
      "5 : Accuracy df_dev: 62.570574559946856 %\n"
     ]
    }
   ],
   "source": [
    "# Predict values for dev dataset using prob(pos|all_words)\n",
    "accuracy_normal = []\n",
    "df_dev_arr = np.array_split(df_dev, 5)\n",
    "ctr = 0\n",
    "\n",
    "print(\"Accuracy using 5-Fold Cross Validation:\")\n",
    "\n",
    "for df in df_dev_arr:\n",
    "    count = 0\n",
    "    ctr += 1\n",
    "    predicted_sentiments = []\n",
    "    prob_pos_g_wir = dict()\n",
    "    prob_neg_g_wir = dict()\n",
    "    \n",
    "    for ind in df.index:\n",
    "        numPos = 0.00\n",
    "        numNeg = 0.00\n",
    "        \n",
    "        review_set = set(df['review'][ind].lower().split())\n",
    "        for word in review_set:\n",
    "            if word in prob_word:\n",
    "                if word not in prob_word_g_pos:\n",
    "                    numNeg = 0\n",
    "                elif word not in prob_word_g_neg:\n",
    "                    numPos = 0\n",
    "                else:\n",
    "                    numPos = numPos + math.log(prob_word_g_pos[word])\n",
    "                    numNeg = numNeg + math.log(prob_word_g_neg[word])\n",
    "                            \n",
    "        prob_pos_g_wir[ind] = pow(math.e, numPos) * prob_pos_train\n",
    "        prob_neg_g_wir[ind] = pow(math.e, numNeg) * prob_neg_train\n",
    "                            \n",
    "        if(prob_pos_g_wir[ind] < prob_neg_g_wir[ind]):\n",
    "            predicted_sentiments.append(0)\n",
    "        else:\n",
    "            predicted_sentiments.append(1)\n",
    "                                    \n",
    "    df['prediction'] = predicted_sentiments\n",
    "                                                                        \n",
    "    for ind in df.index:\n",
    "        if df['sentiment'][ind] == df['prediction'][ind]:\n",
    "            count += 1\n",
    "                                            \n",
    "    accuracy = count / len(df)\n",
    "    accuracy_normal.append(accuracy)\n",
    "    print (ctr,\": Accuracy df_dev:\",accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Perform given experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.1 Compare the effect of Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate probabilities using Smoothing for:\n",
    "# a) each word given positive\n",
    "# b) each word given negative\n",
    "\n",
    "prob_word_g_pos_smooth = dict()\n",
    "prob_word_g_neg_smooth = dict()\n",
    "\n",
    "for word in final_vocab:\n",
    "    if word in final_vocab_pos:\n",
    "        prob_word_g_pos_smooth[word] = (final_vocab_pos[word]+1) / (df_train_pos_len + len(final_vocab))\n",
    "        \n",
    "    if word in final_vocab_neg:\n",
    "        prob_word_g_neg_smooth[word] = (final_vocab_neg[word]+1) / (df_train_neg_len + len(final_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Smoothing using 5-Fold Cross Validation:\n",
      "1 : Accuracy df_dev: 61.05577689243028 %\n",
      "2 : Accuracy df_dev: 61.68658698539177 %\n",
      "3 : Accuracy df_dev: 63.01460823373174 %\n",
      "4 : Accuracy df_dev: 62.21779548472776 %\n",
      "5 : Accuracy df_dev: 62.3380936565925 %\n"
     ]
    }
   ],
   "source": [
    "# Predict values for dev dataset using prob(pos|all_words)\n",
    "\n",
    "accuracy_smooth = []\n",
    "df_dev_arr = np.array_split(df_dev, 5)\n",
    "ctr = 0\n",
    "\n",
    "print(\"Accuracy after Smoothing using 5-Fold Cross Validation:\")\n",
    "\n",
    "for df in df_dev_arr:\n",
    "    count = 0\n",
    "    ctr += 1\n",
    "    predicted_sentiments = []\n",
    "    prob_pos_g_wir = dict()\n",
    "    prob_neg_g_wir = dict()\n",
    "    \n",
    "    for ind in df.index:\n",
    "        numPos = 0.00\n",
    "        numNeg = 0.00\n",
    "        \n",
    "        review_set = set(df['review'][ind].lower().split())\n",
    "        for word in review_set:\n",
    "            if word in prob_word:\n",
    "                if word not in prob_word_g_pos:\n",
    "                    numNeg = 0\n",
    "                elif word not in prob_word_g_neg:\n",
    "                    numPos = 0\n",
    "                else:\n",
    "                    numPos = numPos + math.log(prob_word_g_pos_smooth[word])\n",
    "                    numNeg = numNeg + math.log(prob_word_g_neg_smooth[word])\n",
    "                            \n",
    "        prob_pos_g_wir[ind] = pow(math.e, numPos) * prob_pos_train\n",
    "        prob_neg_g_wir[ind] = pow(math.e, numNeg) * prob_neg_train\n",
    "                            \n",
    "        if(prob_pos_g_wir[ind] < prob_neg_g_wir[ind]):\n",
    "            predicted_sentiments.append(0)\n",
    "        else:\n",
    "            predicted_sentiments.append(1)\n",
    "                                    \n",
    "    df['prediction'] = predicted_sentiments\n",
    "                                                                        \n",
    "    for ind in df.index:\n",
    "        if df['sentiment'][ind] == df['prediction'][ind]:\n",
    "            count += 1\n",
    "                                            \n",
    "    accuracy = count / len(df)\n",
    "    accuracy_smooth.append(accuracy)\n",
    "    print (ctr,\": Accuracy df_dev:\",accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the given dev dataset, accuracy is better without smoothing\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracy values for normal and after smoothing\n",
    "\n",
    "betterNormal = 0\n",
    "betterSmoothing = 0\n",
    "\n",
    "for i in range(len(accuracy_normal)):\n",
    "    if accuracy_normal[i] > accuracy_smooth[i]:\n",
    "        betterNormal += 1\n",
    "    else:\n",
    "        betterSmoothing +=1\n",
    "\n",
    "if(betterNormal > betterSmoothing):\n",
    "    print(\"For the given dev dataset, accuracy is better without smoothing\")\n",
    "else:\n",
    "    print(\"For the given dev dataset, accuracy is better with smoothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.2 Derive Top 10 words that predicts positive and negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prob given word for all vocab\n",
    "\n",
    "prob_pos_given_word = dict()\n",
    "prob_neg_given_word = dict()\n",
    "\n",
    "for word in final_vocab:\n",
    "    if word in final_vocab_pos:\n",
    "        prob_pos_given_word[word] = (prob_word_g_pos[word] * prob_pos_train) / prob_word[word]\n",
    "    if word in final_vocab_neg:\n",
    "        prob_neg_given_word[word] = (prob_word_g_neg[word] * prob_neg_train) / prob_word[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words predicting positive class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('doktor', 1.0),\n",
       " ('mccartney', 1.0),\n",
       " ('brownstone', 1.0),\n",
       " ('unwillingly', 1.0),\n",
       " ('nord', 1.0),\n",
       " (\"gilliam's\", 1.0),\n",
       " ('stitzer', 1.0),\n",
       " ('apatow', 1.0),\n",
       " ('edie', 1.0),\n",
       " ('shimmering', 1.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top 10 words predicting positive class\n",
    "print(\"Top 10 words predicting positive class:\")\n",
    "prob_pos_given_word = sorted(prob_pos_given_word.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "prob_pos_given_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words predicting negative class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('recoil', 1.0),\n",
       " ('clowns', 1.0),\n",
       " ('unintended', 1.0),\n",
       " ('dorff', 1.0),\n",
       " ('slater', 1.0),\n",
       " ('kareena', 1.0),\n",
       " ('atari', 1.0),\n",
       " ('kargil', 1.0),\n",
       " ('weisz', 1.0),\n",
       " ('2/10', 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top 10 words predicting negative class\n",
    "print(\"Top 10 words predicting negative class:\")\n",
    "prob_neg_given_word = sorted(prob_neg_given_word.items(), key=operator.itemgetter(1), reverse=True)\n",
    "prob_neg_given_word[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Calculate accuracy using test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy df_test: 61.41233276330349 %\n"
     ]
    }
   ],
   "source": [
    "# Predict values for test dataset using optimal values : prob(pos|all_words)\n",
    "\n",
    "predicted_sentiments = []\n",
    "prob_pos_g_wir = dict()\n",
    "prob_neg_g_wir = dict()\n",
    "\n",
    "if(betterNormal < betterSmoothing):\n",
    "    prob_word_g_pos = prob_word_g_pos_smooth\n",
    "\n",
    "for ind in df_test.index:\n",
    "    numPos = 0.00\n",
    "    numNeg = 0.00\n",
    "    \n",
    "    review_set = set(df_test['review'][ind].lower().split())\n",
    "    for word in review_set:\n",
    "        if word in prob_word:\n",
    "            if word not in prob_word_g_pos:\n",
    "                numNeg = 0\n",
    "            elif word not in prob_word_g_neg:\n",
    "                numPos = 0\n",
    "            else:\n",
    "                numPos = numPos + math.log(prob_word_g_pos[word])\n",
    "                numNeg = numNeg + math.log(prob_word_g_neg[word])\n",
    "    \n",
    "    prob_pos_g_wir[ind] = pow(math.e, numPos) * prob_pos_train\n",
    "    prob_neg_g_wir[ind] = pow(math.e, numNeg) * prob_neg_train\n",
    "    \n",
    "    if(prob_pos_g_wir[ind] < prob_neg_g_wir[ind]):\n",
    "        predicted_sentiments.append(0)\n",
    "    else:\n",
    "        predicted_sentiments.append(1)\n",
    "        \n",
    "df_test['prediction'] = predicted_sentiments\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ind in df_test.index:\n",
    "    if df_test['sentiment'][ind] == df_test['prediction'][ind]:\n",
    "        count += 1\n",
    "        \n",
    "accuracy = count / len(df_test)\n",
    "print (\"Accuracy df_test:\",accuracy*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
